{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Weather model\n",
    "\n",
    "Clustering is a Machine Learning technique that involves the grouping of data points. In theory, data points that are in the same group should have similar properties and/or features, while data points in different groups should have highly dissimilar properties and/or features. (https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)\n",
    "\n",
    "Basic Algorithm for K-Means:\n",
    "* Step 1: Randomly pick K points to place K centroids\n",
    "* Step 2: Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.\n",
    "* Step 3: Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
    "* Step 4: Reassign every point once again to the closest centroid.\n",
    "* Step 5: Repeat steps 3-4 until no point changes which centroid it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Model\n",
    "We will model a simple weather system and try to predict the temperature on each day given the following information.\n",
    "\n",
    "1. Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
    "2. The first day in our sequence has an 80% chance of being cold.\n",
    "3. A cold day has a 30% chance of being followed by a hot day.\n",
    "4. A hot day has a 20% chance of being followed by a cold day.\n",
    "5. On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions  # making a shortcut for later on\n",
    "initial_distribution = tfd.Categorical(probs=[0.2, 0.8])  # Refer to point 2 above\n",
    "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
    "                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # refer to point 5 above\n",
    "\n",
    "# the loc argument represents the mean and the scale is the standard devitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Markov model distribution.\n",
    "\n",
    "Inherits From: Distribution\n",
    "\n",
    "\n",
    "tfp.distributions.HiddenMarkovModel(\\\n",
    "    initial_distribution,\\\n",
    "    transition_distribution,\\\n",
    "    observation_distribution,\\\n",
    "    num_steps,\\\n",
    "    validate_args=False,\\\n",
    "    allow_nan_stats=True,\\\n",
    "    time_varying_transition_distribution=False,\\\n",
    "    time_varying_observation_distribution=False,\\\n",
    "    mask=None,\\\n",
    "    name='HiddenMarkovModel'\\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of steps represents the number of days that we would like to predict information for. In this case we've chosen 7, an entire week.\n",
    "\n",
    "To get the expected temperatures on each day we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.       10.5       9.75      9.375001  9.1875    9.093751  9.046875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730194695.414918   90987 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3620 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "mean = model.mean()\n",
    "\n",
    "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n",
    "# from within a session to see the value of this tensor\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
    "with tf.compat.v1.Session() as sess:  \n",
    "  print(mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days:\n",
    "1. 12\n",
    "2. 10.5\n",
    "3. 9.75\n",
    "4. 9.37\n",
    "5. 9.1875\n",
    "7. 9.09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
